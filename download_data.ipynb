{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BEARER_TOKEN from key.json\n",
    "with open('key.json') as f:\n",
    "\tkey = json.load(f)\n",
    "\tbearer_token = key['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search, num_tweets = 5):\n",
    "\t# Create the url\n",
    "\turl = 'https://api.twitter.com/1.1/search/tweets.json?result_type=popular&q='+ search + '&max_results=' + str(num_tweets)\n",
    "\t# Create request headers\n",
    "\theaders = {\n",
    "\t\t'authorization': 'Bearer ' + bearer_token,\n",
    "\t\t'user-agent': 'v2FilteredStreamPython',\n",
    "\t}\n",
    "\t# Make the request\n",
    "\tresponse = requests.get(url, headers=headers)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheels_json = get_tweets('wheel', 100)\n",
    "doors_json = get_tweets('door', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to json file\n",
    "with open('wheels.json', 'w') as f:\n",
    "\tjson.dump(wheels_json, f)\n",
    "with open('doors.json', 'w') as f:\n",
    "\tjson.dump(doors_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download full posts from reddit search results\n",
    "def get_reddit_data(search, num_posts = 5):\n",
    "\t# Create the url for the search also get the posts text\n",
    "\turl = 'https://www.reddit.com/search.json?q=' + search + '&sort=top&t=all&limit=' + str(num_posts)\n",
    "\t# Make the request\n",
    "\tresponse = requests.get(url)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheels_reddit = get_reddit_data('wheels', 100)\n",
    "doors_reddit = get_reddit_data('doors', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wheels_submissions.json', 'w') as f:\n",
    "\tjson.dump(wheels_reddit, f)\n",
    "with open('doors_submissions.json', 'w') as f:\n",
    "\tjson.dump(doors_reddit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the posts text\n",
    "for post in wheels_reddit:\n",
    "\tpost_id = post['data']['id']\n",
    "\t# Get post\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_data(search, num_posts = 5):\n",
    "\t# Create the url for the search also get the posts text\n",
    "\turl = 'https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch=' + search + '&format=json&srlimit=' + str(num_posts)\n",
    "\t# Make the request\n",
    "\tresponse = requests.get(url)\n",
    "\treturn response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheels_wiki = get_wikipedia_data('wheels', 100)\n",
    "doors_wiki = get_wikipedia_data('doors', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wheels_wiki.json', 'w') as f:\n",
    "\tjson.dump(wheels_wiki, f)\n",
    "with open('doors_wiki.json', 'w') as f:\n",
    "\tjson.dump(doors_wiki, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the pages from wikipedia\n",
    "for page in wheels_wiki['query']['search']:\n",
    "\turl = 'https://en.wikipedia.org/wiki/' + page['title']\n",
    "\tresponse = requests.get(url)\n",
    "\twith open('wheels_wiki_pages/' + page['title'] + '.html', 'w') as f:\n",
    "\t\tf.write(response.text)\n",
    "\ttime.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in doors_wiki['query']['search']:\n",
    "\turl = 'https://en.wikipedia.org/wiki/' + page['title']\n",
    "\tresponse = requests.get(url)\n",
    "\twith open('doors_wiki_pages/' + page['title'] + '.html', 'w') as f:\n",
    "\t\tf.write(response.text)\n",
    "\ttime.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
