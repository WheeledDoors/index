{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8aaef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f6f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab03e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12c6d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lemcm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lemcm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lemcm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    " \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da2c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"model_dev_data.csv\", encoding = \"ISO-8859-1\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, (0,5)]\n",
    "\n",
    "df.columns = [\"Rating\",\"Text\"]\n",
    "\n",
    "df[\"Rating\"] = df[\"Rating\"].map({4 : 1, 0:0}) #mapping positive to 1 instead of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774209cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a554b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(100000, random_state=0) #scaling down so processing time is achievable \n",
    "# df = df.sample(20, random_state=0) #scaling down so processing time is achievable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f404d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  df[\"Text\"], df[\"Rating\"], test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219fcf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdaa53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokens(row):\n",
    "    return word_tokenize(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8371004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df = df.apply(word_tokenize)\n",
    "    df = df.map(lambda x: [i.lower() for i in x if i.lower() not in stop_words])\n",
    "    df = df.map(lambda x: [lemmatizer.lemmatize(i) for i in x if i.lower() if i.isalnum()])\n",
    "    df = df.map(lambda x: ' '.join(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18455b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2c5860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bfb4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_1 = X_test[:2]\n",
    "# y_test_1 = y_test[:2]\n",
    "\n",
    "\n",
    "# X_test_2 = X_test[2:4].reset_index(drop=True)\n",
    "# y_test_2 = y_test[2:4].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# X_test_3 = X_test[4:].reset_index(drop=True)\n",
    "# y_test_3 = y_test[4:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e74de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = X_test[:500]\n",
    "y_test_1 = y_test[:500]\n",
    "\n",
    "\n",
    "X_test_2 = X_test[500:1000].reset_index(drop=True)\n",
    "y_test_2 = y_test[500:1000].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_test_3 = X_test[1000:1500].reset_index(drop=True)\n",
    "y_test_3 = y_test[1000:1500].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd8be1",
   "metadata": {},
   "source": [
    "## TFIDF RF or SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c20ba9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b87c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e49d664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = TfidfVectorizer()\n",
    "\n",
    "x_train_tfidf = vect2.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d57ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1_tfidf = vect2.transform(X_test_1)\n",
    "x_test_2_tfidf = vect2.transform(X_test_2)\n",
    "x_test_3_tfidf = vect2.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad215b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96065a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RF: TFIDF\n",
    "clf = RF()\n",
    "clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "filename = 'SVC_TFIDF.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f47a2cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.768\n",
      "precision is 0.8170212765957446 \n",
      "recall is 0.7245283018867924\n"
     ]
    }
   ],
   "source": [
    "#Test set 1:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_1_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, TFIDF\",1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98df9b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.73\n",
      "precision is 0.723404255319149 \n",
      "recall is 0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "#Test set 1:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_2_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, TFIDF\",2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c80fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SVC: TFIDF\n",
    "clf = RF()\n",
    "clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "filename = 'SVC_TFIDF.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b54d07bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.768\n",
      "precision is 0.8143459915611815 \n",
      "recall is 0.7283018867924528\n"
     ]
    }
   ],
   "source": [
    "#Test set 1:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_1_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, TFIDF\",1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b115c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.738\n",
      "precision is 0.746606334841629 \n",
      "recall is 0.6875\n"
     ]
    }
   ],
   "source": [
    "#Test set 2:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_2_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, TFIDF\",2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16e9ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.768\n",
      "precision is 0.784688995215311 \n",
      "recall is 0.6978723404255319\n"
     ]
    }
   ],
   "source": [
    "#Test set 3:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_3_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, TFIDF\",3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f903c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37387152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6370284",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SVC_TFIDF.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc2be076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.766\n",
      "precision is 0.8057851239669421 \n",
      "recall is 0.7358490566037735\n"
     ]
    }
   ],
   "source": [
    "#Test set 1:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_1_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, TFIDF\",1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ff11b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.756\n",
      "precision is 0.7610619469026548 \n",
      "recall is 0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "#Test set 1:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_2_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, TFIDF\",2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c2f1b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8\n",
      "precision is 0.8054298642533937 \n",
      "recall is 0.7574468085106383\n"
     ]
    }
   ],
   "source": [
    "#Test set 3:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_3_tfidf) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, TFIDF\",3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5eab22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258c784",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c925705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as gensim_api\n",
    "embeddings = gensim_api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "476bad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vec_clean(df):\n",
    "    docs_vects = pd.DataFrame()\n",
    "    for i in range(0, len(df)):\n",
    "        temp = pd.DataFrame()\n",
    "        for word in df[i].split(\" \"):\n",
    "            try:\n",
    "                word_vec = embeddings[word]\n",
    "                temp = temp.append(pd.Series(word_vec), ignore_index=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        doc_vect = temp.mean()\n",
    "        docs_vects = docs_vects.append(doc_vect, ignore_index = True)\n",
    "    return docs_vects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38c51e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = word_to_vec_clean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58a1a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.to_csv(\"X_train_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68c95616",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "X_test_1_vec = word_to_vec_clean(X_test_1)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "647a3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2_vec = word_to_vec_clean(X_test_2)\n",
    "X_test_3_vec = word_to_vec_clean(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc54a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1_vec.to_csv(\"X_test_1_vec.csv\")\n",
    "X_test_2_vec.to_csv(\"X_test_2_vec.csv\")\n",
    "X_test_3_vec.to_csv(\"X_test_3_vec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3181e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = pd.read_csv(\"X_train_vec.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4bef353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1_vec = pd.read_csv(\"X_test_1_vec.csv\", index_col = \"Unnamed: 0\")\n",
    "X_test_2_vec = pd.read_csv(\"X_test_2_vec.csv\", index_col = \"Unnamed: 0\")\n",
    "X_test_3_vec = pd.read_csv(\"X_test_3_vec.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99302ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index_train = np.where(X_train_vec.isna().any(axis=1) == True)[0]\n",
    "\n",
    "drop_index_test_1 = np.where(X_test_1_vec.isna().any(axis=1) == True)[0]\n",
    "drop_index_test_2 = np.where(X_test_2_vec.isna().any(axis=1) == True)[0]\n",
    "drop_index_test_3 =  np.where(X_test_3_vec.isna().any(axis=1) == True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52a72fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = X_train_vec.drop(drop_index_train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca1ee8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vec = y_train.drop(drop_index_train).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbfa6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1_vec = X_test_1_vec.drop(drop_index_test_1).reset_index(drop=True)\n",
    "X_test_2_vec = X_test_2_vec.drop(drop_index_test_2).reset_index(drop=True)\n",
    "X_test_3_vec = X_test_3_vec.drop(drop_index_test_3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38c2ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1_vec = y_test_1.drop(drop_index_test_1).reset_index(drop=True)\n",
    "y_test_2_vec = y_test_2.drop(drop_index_test_2).reset_index(drop=True)\n",
    "y_test_3_vec = y_test_3.drop(drop_index_test_3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10d295c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_time = (end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8e4ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19e12415",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pre.MinMaxScaler()\n",
    "X_train_NB = scaler.fit_transform(X_train_vec)\n",
    "X_test_NB_1 = scaler.fit_transform(X_test_1_vec)\n",
    "X_test_NB_2 = scaler.fit_transform(X_test_2_vec)\n",
    "X_test_NB_3 = scaler.fit_transform(X_test_3_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aad4bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NB: WORDVEC\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_NB, y_train_vec)\n",
    "\n",
    "\n",
    "filename = 'NB_Word2Vec.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b513161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.5665322580645161\n",
      "precision is 0.5524017467248908 \n",
      "recall is 0.9619771863117871\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_NB_1) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"NB, WORDVEC\", 1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f80eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.597165991902834\n",
      "precision is 0.5520833333333334 \n",
      "recall is 0.8870292887029289\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_NB_2) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"NB, WORDVEC\", 2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "306c466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6016260162601627\n",
      "precision is 0.5508021390374331 \n",
      "recall is 0.8803418803418803\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_NB_3) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"NB, WORDVEC\", 3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "089b2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logistic Regression: WORDVEC\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vec, y_train_vec)\n",
    "\n",
    "\n",
    "filename = 'Log_Word2Vec.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "647422d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7137096774193549\n",
      "precision is 0.712280701754386 \n",
      "recall is 0.7718631178707225\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_1_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"Log, WORDVEC\", 1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f46af2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6700404858299596\n",
      "precision is 0.6417910447761194 \n",
      "recall is 0.7196652719665272\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_2_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"Log, WORDVEC\", 2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8babf89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7215447154471545\n",
      "precision is 0.691699604743083 \n",
      "recall is 0.7478632478632479\n"
     ]
    }
   ],
   "source": [
    "#Test set 3:\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_3_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time= (end - start)/60\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"Log, WORDVEC\",3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4321725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d0b6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RF: WORDVEC\n",
    "\n",
    "clf = RF()\n",
    "clf.fit(X_train_vec, y_train_vec)\n",
    "\n",
    "\n",
    "filename = 'RF_Word2Vec.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ba9a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6754032258064516\n",
      "precision is 0.6554878048780488 \n",
      "recall is 0.8174904942965779\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_1_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, WORDVEC\", 1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d2c289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6295546558704453\n",
      "precision is 0.5897435897435898 \n",
      "recall is 0.7698744769874477\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_2_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, WORDVEC\", 2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c6b9b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6869918699186992\n",
      "precision is 0.636986301369863 \n",
      "recall is 0.7948717948717948\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_3_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, WORDVEC\", 3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8340e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SVC: WORDVEC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train_vec, y_train_vec)\n",
    "\n",
    "\n",
    "filename = 'SVC_Word2Vec.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91e51f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7439516129032258\n",
      "precision is 0.7463768115942029 \n",
      "recall is 0.7832699619771863\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_1_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, WORDVEC\", 1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f1a79ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6862348178137652\n",
      "precision is 0.65 \n",
      "recall is 0.7615062761506276\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_2_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, WORDVEC\", 2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb8ab803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.7459349593495935\n",
      "precision is 0.7154150197628458 \n",
      "recall is 0.7735042735042735\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(X_test_3_vec) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3_vec, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3_vec, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, WORDVEC\", 3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb217546",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2349738",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "69482c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "x_train_bow = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd48c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_bow_1 = vect.transform(X_test_1)\n",
    "x_test_bow_2 = vect.transform(X_test_2)\n",
    "x_test_bow_3 = vect.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c2db3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RF: BOW\n",
    "\n",
    "clf = RF()\n",
    "clf.fit(x_train_bow, y_train)\n",
    "\n",
    "filename = 'RF_BOW.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7d1a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.772\n",
      "precision is 0.7870722433460076 \n",
      "recall is 0.7811320754716982\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_bow_1) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, BOW\", 1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b50cb77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.728\n",
      "precision is 0.7166666666666667 \n",
      "recall is 0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_bow_2) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, BOW\", 2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2a6c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.726\n",
      "precision is 0.6991869918699187 \n",
      "recall is 0.7319148936170212\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_bow_3) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"RF, BOW\", 3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d929d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RF: SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(x_train_bow, y_train)\n",
    "\n",
    "filename = 'SVC_BOW.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6d60ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.762\n",
      "precision is 0.8067226890756303 \n",
      "recall is 0.7245283018867924\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_bow_1) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_1, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_1, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, BOW\", 1, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5479468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.752\n",
      "precision is 0.7660550458715596 \n",
      "recall is 0.6958333333333333\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_bow_2) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_2, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_2, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, BOW\", 2, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "895e4972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.786\n",
      "precision is 0.7962962962962963 \n",
      "recall is 0.7319148936170212\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = clf.predict(x_test_bow_3) #prediction from model\n",
    "end = time.time()\n",
    "accuracy = accuracy_score(y_test_3, y_pred)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test_3, y_pred)\n",
    "\n",
    "precision = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "print(f\"precision is {precision} \")\n",
    "\n",
    "recall = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "print(f\"recall is {recall}\")\n",
    "\n",
    "f = 2*(precision * recall)/(precision + recall)\n",
    "\n",
    "tot_time =  ((end-start)/60) + vec_time\n",
    "\n",
    "results_df = results_df.append(pd.Series([\"SVC, BOW\", 3, precision, recall, accuracy, f, tot_time]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5a1df1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d715f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd5f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
